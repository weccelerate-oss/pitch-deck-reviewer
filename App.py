"""
××¢×¨×›×ª ×¡×§×™×¨×ª ××¦×’×•×ª AI - ×’×¨×¡×” ×¡×•×¤×™×ª
Pitch Deck Review System with Native PowerPoint Comments

×ª××™×›×” ×‘×”×¢×¨×•×ª PowerPoint ××§×•×¨×™×•×ª (Modern Comments)
×¢× ×××©×§ ×¢×‘×¨×™×ª ××ª×•×§×Ÿ
"""

import streamlit as st
import pandas as pd
from pptx import Presentation
from pptx.util import Pt, Inches, Emu
from pptx.opc.package import Part
from pptx.opc.packuri import PackURI
from docx import Document
import google.generativeai as genai
import json
import io
import re
import zipfile
from datetime import datetime
from lxml import etree
import uuid
import copy


# ============================================================
# ×”×’×“×¨×•×ª API
# ============================================================
GEMINI_API_KEY = "AIzaSyBJstgLpy_6W8OkQTD6t8HmfYTLL1sTLXE"
genai.configure(api_key=GEMINI_API_KEY)


# ============================================================
# ×§×‘×•×¢×™× XML ×œ×”×¢×¨×•×ª PowerPoint ××•×“×¨× ×™×•×ª
# ============================================================
# Modern Comments (Office 2019+)
MODERN_COMMENTS_NS = "http://schemas.microsoft.com/office/powerpoint/2018/8/main"
MODERN_COMMENTS_REL_TYPE = "http://schemas.microsoft.com/office/2018/10/relationships/comments"
MODERN_COMMENTS_CONTENT_TYPE = "application/vnd.ms-powerpoint.comments+xml"

# Legacy Comments (Office 2007-2016)
LEGACY_COMMENTS_NS = "http://schemas.openxmlformats.org/presentationml/2006/main"
LEGACY_COMMENTS_REL_TYPE = "http://schemas.openxmlformats.org/officeDocument/2006/relationships/comments"
LEGACY_COMMENTS_CONTENT_TYPE = "application/vnd.openxmlformats-officedocument.presentationml.comments+xml"
LEGACY_AUTHORS_CONTENT_TYPE = "application/vnd.openxmlformats-officedocument.presentationml.commentAuthors+xml"
LEGACY_AUTHORS_REL_TYPE = "http://schemas.openxmlformats.org/officeDocument/2006/relationships/commentAuthors"

# Namespaces
NSMAP_LEGACY = {
    'p': 'http://schemas.openxmlformats.org/presentationml/2006/main',
    'r': 'http://schemas.openxmlformats.org/officeDocument/2006/relationships',
}


# ============================================================
# ×”×’×“×¨×•×ª ×¢××•×“ Streamlit
# ============================================================
st.set_page_config(
    page_title="×¡×§×™×¨×ª ××¦×’×•×ª AI",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)


# ============================================================
# CSS ××ª×§×“× - ×¢×™×¦×•×‘ ××¨×©×™× ×•××§×¦×•×¢×™
# ============================================================
st.markdown("""
<style>
/* ===== ×™×™×‘×•× ×¤×•× ×˜×™× ===== */
@import url('https://fonts.googleapis.com/css2?family=Heebo:wght@300;400;500;600;700;800;900&display=swap');

/* ===== ××©×ª× ×™ ×¢×™×¦×•×‘ ===== */
:root {
    --bg-dark: #0f0f23;
    --bg-card: #1a1a2e;
    --bg-card-hover: #232342;
    --accent-primary: #6366f1;
    --accent-secondary: #8b5cf6;
    --accent-tertiary: #a855f7;
    --accent-success: #10b981;
    --accent-warning: #f59e0b;
    --accent-danger: #ef4444;
    --accent-info: #3b82f6;
    --text-primary: #f8fafc;
    --text-secondary: #94a3b8;
    --text-muted: #64748b;
    --border-color: #334155;
    --glow-primary: rgba(99, 102, 241, 0.4);
    --glow-success: rgba(16, 185, 129, 0.4);
    --radius-sm: 8px;
    --radius-md: 12px;
    --radius-lg: 16px;
    --radius-xl: 24px;
    --shadow-sm: 0 2px 8px rgba(0, 0, 0, 0.3);
    --shadow-md: 0 4px 20px rgba(0, 0, 0, 0.4);
    --shadow-lg: 0 8px 40px rgba(0, 0, 0, 0.5);
    --shadow-glow: 0 0 30px var(--glow-primary);
}

/* ===== ××™×¤×•×¡ ×•×”×’×“×¨×•×ª ×’×œ×•×‘×œ×™×•×ª ===== */
html, body, .stApp {
    direction: rtl !important;
    text-align: right !important;
    font-family: 'Heebo', -apple-system, BlinkMacSystemFont, sans-serif !important;
    background: linear-gradient(135deg, var(--bg-dark) 0%, #16162e 50%, #1a1a3e 100%) !important;
    color: var(--text-primary) !important;
}

* {
    line-height: 1.7 !important;
}

/* ===== ×ª×•×›×Ÿ ×¨××©×™ ===== */
.main .block-container {
    direction: rtl !important;
    text-align: right !important;
    padding: 2rem 3rem !important;
    max-width: 1400px !important;
    background: transparent !important;
}

/* ===== ×¡×¨×’×œ ×¦×“ ××¢×•×¦×‘ ===== */
[data-testid="stSidebar"] {
    direction: rtl !important;
    background: linear-gradient(180deg, #0c0c1d 0%, #12122a 50%, #0a0a1a 100%) !important;
    border-left: 1px solid var(--border-color) !important;
}

[data-testid="stSidebar"]::before {
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    height: 3px;
    background: linear-gradient(90deg, var(--accent-primary), var(--accent-secondary), var(--accent-tertiary));
}

[data-testid="stSidebar"] > div:first-child {
    direction: rtl !important;
    padding: 2rem 1.5rem !important;
}

[data-testid="stSidebar"] * {
    direction: rtl !important;
    text-align: right !important;
}

[data-testid="stSidebar"] .stMarkdown p,
[data-testid="stSidebar"] .stMarkdown span,
[data-testid="stSidebar"] .stMarkdown h1,
[data-testid="stSidebar"] .stMarkdown h2,
[data-testid="stSidebar"] .stMarkdown h3 {
    color: var(--text-primary) !important;
}

[data-testid="stSidebar"] hr {
    border: none !important;
    height: 1px !important;
    background: linear-gradient(90deg, transparent, var(--border-color), transparent) !important;
    margin: 1.5rem 0 !important;
}

/* ===== ××“×“×™× ×‘×¡×¨×’×œ ×¦×“ - ×ª×™×§×•×Ÿ ×§×¨×™××•×ª ===== */
[data-testid="stSidebar"] [data-testid="stMetric"] {
    background: linear-gradient(135deg, rgba(99, 102, 241, 0.15) 0%, rgba(139, 92, 246, 0.1) 100%) !important;
    border: 1px solid rgba(99, 102, 241, 0.3) !important;
    border-radius: var(--radius-md) !important;
    padding: 1rem !important;
    margin: 0.5rem 0 !important;
}

[data-testid="stSidebar"] [data-testid="stMetricLabel"] {
    color: var(--text-secondary) !important;
    font-size: 0.85rem !important;
    font-weight: 500 !important;
}

[data-testid="stSidebar"] [data-testid="stMetricValue"] {
    color: var(--text-primary) !important;
    font-size: 1.8rem !important;
    font-weight: 700 !important;
    text-shadow: 0 0 20px var(--glow-primary) !important;
}

/* ===== ×›×•×ª×¨×•×ª ===== */
h1, h2, h3, h4, h5, h6 {
    color: var(--text-primary) !important;
    font-weight: 700 !important;
    margin-bottom: 1rem !important;
    direction: rtl !important;
    text-align: right !important;
}

h1 { font-size: 2.5rem !important; }
h2 { font-size: 1.8rem !important; }
h3 { font-size: 1.4rem !important; }

/* ===== ×¤×¡×§××•×ª ×•×˜×§×¡×˜ ===== */
p, span, div, label, li {
    direction: rtl !important;
    text-align: right !important;
    color: var(--text-secondary) !important;
}

.stMarkdown p {
    color: var(--text-secondary) !important;
}

/* ===== ×›×¨×˜×™×¡ ×›×•×ª×¨×ª ×¨××©×™×ª ===== */
.main-header {
    background: linear-gradient(135deg, rgba(99, 102, 241, 0.1) 0%, rgba(139, 92, 246, 0.05) 100%);
    border: 1px solid rgba(99, 102, 241, 0.2);
    border-radius: var(--radius-xl);
    padding: 3rem 2rem;
    margin-bottom: 2rem;
    text-align: center;
    position: relative;
    overflow: hidden;
}

.main-header::before {
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    height: 4px;
    background: linear-gradient(90deg, var(--accent-primary), var(--accent-secondary), var(--accent-tertiary), var(--accent-primary));
    background-size: 300% 100%;
    animation: gradient-flow 5s ease infinite;
}

@keyframes gradient-flow {
    0%, 100% { background-position: 0% 50%; }
    50% { background-position: 100% 50%; }
}

.main-title {
    font-size: 3rem !important;
    font-weight: 900 !important;
    background: linear-gradient(135deg, #fff 0%, #a5b4fc 50%, #c4b5fd 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-clip: text;
    margin-bottom: 0.5rem !important;
    text-shadow: none;
    letter-spacing: -1px;
}

.sub-title {
    color: var(--text-secondary) !important;
    font-size: 1.2rem !important;
    font-weight: 400 !important;
    margin: 0 !important;
}

/* ===== ×©×“×•×ª ×§×œ×˜ ===== */
.stTextInput > div,
.stTextArea > div,
.stSelectbox > div {
    direction: rtl !important;
}

.stTextInput input,
.stTextArea textarea {
    direction: rtl !important;
    text-align: right !important;
    background: var(--bg-card) !important;
    border: 2px solid var(--border-color) !important;
    border-radius: var(--radius-md) !important;
    color: var(--text-primary) !important;
    padding: 0.875rem 1rem !important;
    font-family: 'Heebo', sans-serif !important;
    font-size: 1rem !important;
    transition: all 0.3s ease !important;
}

.stTextInput input:focus,
.stTextArea textarea:focus {
    border-color: var(--accent-primary) !important;
    box-shadow: 0 0 0 3px rgba(99, 102, 241, 0.2), var(--shadow-glow) !important;
    outline: none !important;
}

.stTextInput input::placeholder,
.stTextArea textarea::placeholder {
    color: var(--text-muted) !important;
}

/* ===== ×ª×™×‘×•×ª ×‘×—×™×¨×” ===== */
.stSelectbox [data-baseweb="select"] {
    direction: rtl !important;
}

.stSelectbox [data-baseweb="select"] > div {
    background: var(--bg-card) !important;
    border: 2px solid var(--border-color) !important;
    border-radius: var(--radius-md) !important;
    color: var(--text-primary) !important;
    direction: rtl !important;
    text-align: right !important;
}

.stSelectbox [data-baseweb="select"] > div:hover {
    border-color: var(--accent-primary) !important;
}

/* ===== ×”×¢×œ××ª ×§×‘×¦×™× ===== */
[data-testid="stFileUploader"] {
    direction: rtl !important;
}

[data-testid="stFileUploader"] section {
    direction: rtl !important;
    background: linear-gradient(135deg, rgba(99, 102, 241, 0.05) 0%, rgba(139, 92, 246, 0.03) 100%) !important;
    border: 2px dashed var(--border-color) !important;
    border-radius: var(--radius-lg) !important;
    padding: 2.5rem !important;
    transition: all 0.3s ease !important;
}

[data-testid="stFileUploader"] section:hover {
    border-color: var(--accent-primary) !important;
    background: linear-gradient(135deg, rgba(99, 102, 241, 0.1) 0%, rgba(139, 92, 246, 0.05) 100%) !important;
    box-shadow: var(--shadow-glow) !important;
}

[data-testid="stFileUploader"] section > div {
    text-align: center !important;
}

[data-testid="stFileUploader"] small {
    color: var(--text-muted) !important;
}

/* ===== ×›×¤×ª×•×¨×™× ===== */
.stButton > button {
    direction: rtl !important;
    font-family: 'Heebo', sans-serif !important;
    font-weight: 600 !important;
    font-size: 1rem !important;
    border-radius: var(--radius-md) !important;
    padding: 0.875rem 2rem !important;
    transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1) !important;
    position: relative !important;
    overflow: hidden !important;
}

.stButton > button[kind="primary"] {
    background: linear-gradient(135deg, var(--accent-primary) 0%, var(--accent-secondary) 100%) !important;
    border: none !important;
    color: white !important;
    box-shadow: 0 4px 15px rgba(99, 102, 241, 0.4) !important;
}

.stButton > button[kind="primary"]:hover {
    transform: translateY(-3px) !important;
    box-shadow: 0 8px 25px rgba(99, 102, 241, 0.5), var(--shadow-glow) !important;
}

.stButton > button[kind="primary"]:active {
    transform: translateY(-1px) !important;
}

.stButton > button[kind="secondary"] {
    background: transparent !important;
    border: 2px solid var(--border-color) !important;
    color: var(--text-primary) !important;
}

.stButton > button[kind="secondary"]:hover {
    border-color: var(--accent-primary) !important;
    background: rgba(99, 102, 241, 0.1) !important;
}

.stButton > button:disabled {
    background: var(--bg-card) !important;
    border: 2px solid var(--border-color) !important;
    color: var(--text-muted) !important;
    box-shadow: none !important;
    cursor: not-allowed !important;
    opacity: 0.6 !important;
}

/* ===== ×›×¤×ª×•×¨×™ ×”×•×¨×“×” ===== */
[data-testid="stDownloadButton"] > button {
    background: linear-gradient(135deg, var(--accent-success) 0%, #059669 100%) !important;
    border: none !important;
    color: white !important;
    font-weight: 600 !important;
    box-shadow: 0 4px 15px rgba(16, 185, 129, 0.4) !important;
}

[data-testid="stDownloadButton"] > button:hover {
    transform: translateY(-3px) !important;
    box-shadow: 0 8px 25px rgba(16, 185, 129, 0.5), 0 0 30px var(--glow-success) !important;
}

/* ===== ×”×•×“×¢×•×ª ××¢×¨×›×ª ===== */
[data-testid="stAlert"] {
    direction: rtl !important;
    border-radius: var(--radius-md) !important;
    padding: 1rem 1.25rem !important;
    margin: 1rem 0 !important;
    border: none !important;
}

[data-testid="stAlert"] > div {
    direction: rtl !important;
    text-align: right !important;
}

/* ×”×¦×œ×—×” */
.stSuccess, [data-testid="stAlert"][data-baseweb*="positive"] {
    background: linear-gradient(135deg, rgba(16, 185, 129, 0.15) 0%, rgba(16, 185, 129, 0.05) 100%) !important;
    border-right: 4px solid var(--accent-success) !important;
}

.stSuccess p, [data-testid="stAlert"][data-baseweb*="positive"] p {
    color: #6ee7b7 !important;
}

/* ××–×”×¨×” */
.stWarning {
    background: linear-gradient(135deg, rgba(245, 158, 11, 0.15) 0%, rgba(245, 158, 11, 0.05) 100%) !important;
    border-right: 4px solid var(--accent-warning) !important;
}

.stWarning p {
    color: #fcd34d !important;
}

/* ××™×“×¢ */
.stInfo {
    background: linear-gradient(135deg, rgba(59, 130, 246, 0.15) 0%, rgba(59, 130, 246, 0.05) 100%) !important;
    border-right: 4px solid var(--accent-info) !important;
}

.stInfo p {
    color: #93c5fd !important;
}

/* ×©×’×™××” */
.stError {
    background: linear-gradient(135deg, rgba(239, 68, 68, 0.15) 0%, rgba(239, 68, 68, 0.05) 100%) !important;
    border-right: 4px solid var(--accent-danger) !important;
}

.stError p {
    color: #fca5a5 !important;
}

/* ===== ×˜×‘×œ×” ×•×¢×•×¨×š × ×ª×•× ×™× ===== */
[data-testid="stDataEditor"],
[data-testid="stDataFrame"] {
    direction: rtl !important;
    border-radius: var(--radius-lg) !important;
    overflow: hidden !important;
    box-shadow: var(--shadow-lg) !important;
    margin: 1.5rem 0 !important;
    border: 1px solid var(--border-color) !important;
}

[data-testid="stDataEditor"] > div,
[data-testid="stDataFrame"] > div {
    direction: rtl !important;
    background: var(--bg-card) !important;
}

/* ×›×•×ª×¨×•×ª ×˜×‘×œ×” */
[data-testid="stDataEditor"] [role="columnheader"],
[data-testid="stDataFrame"] [role="columnheader"] {
    direction: rtl !important;
    text-align: right !important;
    font-weight: 700 !important;
    padding: 1rem !important;
    background: linear-gradient(135deg, rgba(99, 102, 241, 0.2) 0%, rgba(139, 92, 246, 0.1) 100%) !important;
    color: var(--text-primary) !important;
    border-bottom: 2px solid var(--accent-primary) !important;
    font-size: 0.95rem !important;
}

/* ×ª××™ ×˜×‘×œ×” */
[data-testid="stDataEditor"] [role="gridcell"],
[data-testid="stDataFrame"] [role="gridcell"] {
    direction: rtl !important;
    text-align: right !important;
    padding: 0.875rem 1rem !important;
    color: var(--text-secondary) !important;
    border-bottom: 1px solid var(--border-color) !important;
    background: var(--bg-card) !important;
}

[data-testid="stDataEditor"] [role="gridcell"]:hover,
[data-testid="stDataFrame"] [role="gridcell"]:hover {
    background: var(--bg-card-hover) !important;
}

/* ×©×•×¨×•×ª ×œ×¡×™×¨×•×’×™×Ÿ */
[data-testid="stDataEditor"] [role="row"]:nth-child(even) [role="gridcell"],
[data-testid="stDataFrame"] [role="row"]:nth-child(even) [role="gridcell"] {
    background: rgba(99, 102, 241, 0.03) !important;
}

/* ===== ××“×“×™× ×‘××–×•×¨ ×”×¨××©×™ ===== */
.main [data-testid="stMetric"] {
    background: linear-gradient(135deg, var(--bg-card) 0%, var(--bg-card-hover) 100%) !important;
    border: 1px solid var(--border-color) !important;
    border-radius: var(--radius-md) !important;
    padding: 1.25rem !important;
    box-shadow: var(--shadow-md) !important;
    transition: all 0.3s ease !important;
}

.main [data-testid="stMetric"]:hover {
    border-color: var(--accent-primary) !important;
    box-shadow: var(--shadow-lg), var(--shadow-glow) !important;
    transform: translateY(-2px) !important;
}

.main [data-testid="stMetricLabel"] {
    color: var(--text-secondary) !important;
    font-size: 0.9rem !important;
    font-weight: 500 !important;
}

.main [data-testid="stMetricValue"] {
    color: var(--text-primary) !important;
    font-size: 2rem !important;
    font-weight: 700 !important;
}

/* ===== ××§×¡×¤× ×“×¨ ===== */
.streamlit-expanderHeader {
    direction: rtl !important;
    text-align: right !important;
    font-family: 'Heebo', sans-serif !important;
    font-weight: 600 !important;
    font-size: 1rem !important;
    background: linear-gradient(135deg, var(--bg-card) 0%, var(--bg-card-hover) 100%) !important;
    border: 1px solid var(--border-color) !important;
    border-radius: var(--radius-md) !important;
    padding: 1rem 1.5rem !important;
    color: var(--text-primary) !important;
    transition: all 0.3s ease !important;
}

.streamlit-expanderHeader:hover {
    border-color: var(--accent-primary) !important;
    background: var(--bg-card-hover) !important;
}

.streamlit-expanderContent {
    direction: rtl !important;
    text-align: right !important;
    background: var(--bg-card) !important;
    border: 1px solid var(--border-color) !important;
    border-top: none !important;
    border-radius: 0 0 var(--radius-md) var(--radius-md) !important;
    padding: 1.5rem !important;
}

.streamlit-expanderContent p {
    color: var(--text-secondary) !important;
    margin-bottom: 0.75rem !important;
}

/* ===== ×§×• ×”×¤×¨×“×” ===== */
hr {
    border: none !important;
    height: 1px !important;
    background: linear-gradient(90deg, transparent 0%, var(--border-color) 20%, var(--accent-primary) 50%, var(--border-color) 80%, transparent 100%) !important;
    margin: 2.5rem 0 !important;
}

/* ===== Spinner ===== */
.stSpinner > div {
    direction: rtl !important;
    text-align: right !important;
    color: var(--text-secondary) !important;
}

/* ===== Caption ===== */
.stCaption, [data-testid="stCaptionContainer"] {
    direction: rtl !important;
    text-align: right !important;
    color: var(--text-muted) !important;
    font-size: 0.85rem !important;
}

/* ===== ×¢××•×“×•×ª ===== */
[data-testid="column"] {
    padding: 0.75rem !important;
}

/* ===== ×× ×™××¦×™×•×ª ===== */
@keyframes pulse-glow {
    0%, 100% { box-shadow: 0 0 20px rgba(99, 102, 241, 0.3); }
    50% { box-shadow: 0 0 40px rgba(99, 102, 241, 0.5); }
}

@keyframes float {
    0%, 100% { transform: translateY(0); }
    50% { transform: translateY(-5px); }
}

/* ===== ×¤×¡ ×’×œ×™×œ×” ===== */
::-webkit-scrollbar {
    width: 10px;
    height: 10px;
}

::-webkit-scrollbar-track {
    background: var(--bg-dark);
    border-radius: 5px;
}

::-webkit-scrollbar-thumb {
    background: linear-gradient(135deg, var(--accent-primary) 0%, var(--accent-secondary) 100%);
    border-radius: 5px;
    border: 2px solid var(--bg-dark);
}

::-webkit-scrollbar-thumb:hover {
    background: linear-gradient(135deg, var(--accent-secondary) 0%, var(--accent-tertiary) 100%);
}

/* ===== ×”×ª×××” ×œ××•×‘×™×™×œ ===== */
@media (max-width: 768px) {
    .main .block-container {
        padding: 1rem !important;
    }
    
    .main-title {
        font-size: 2rem !important;
    }
    
    .sub-title {
        font-size: 1rem !important;
    }
    
    .main-header {
        padding: 2rem 1rem !important;
    }
    
    [data-testid="stDataEditor"] {
        font-size: 0.85rem !important;
    }
    
    .stButton > button {
        width: 100% !important;
        padding: 1rem !important;
    }
    
    [data-testid="column"] {
        width: 100% !important;
        margin-bottom: 0.75rem !important;
    }
}

/* ===== ×ª×™×§×•× ×™ RTL × ×•×¡×¤×™× ===== */
[data-testid="stDataEditor"] input,
[data-testid="stDataEditor"] select {
    direction: rtl !important;
    text-align: right !important;
}

/* Fix for select dropdowns */
[data-baseweb="popover"] {
    direction: rtl !important;
}

[data-baseweb="menu"] {
    direction: rtl !important;
}

[data-baseweb="menu"] li {
    direction: rtl !important;
    text-align: right !important;
}
</style>
""", unsafe_allow_html=True)


# ============================================================
# ×¤×•× ×§×¦×™×•×ª ×—×™×œ×•×¥ ×˜×§×¡×˜
# ============================================================

def extract_text_from_shape(shape) -> str:
    """×—×™×œ×•×¥ ×˜×§×¡×˜ ×¨×§×•×¨×¡×™×‘×™ ××¦×•×¨×•×ª."""
    from pptx.enum.shapes import MSO_SHAPE_TYPE
    
    text_parts = []
    
    if hasattr(shape, "text_frame"):
        try:
            text = shape.text_frame.text.strip()
            if text:
                text_parts.append(text)
        except:
            pass
    elif hasattr(shape, "text"):
        try:
            text = shape.text.strip()
            if text:
                text_parts.append(text)
        except:
            pass
    
    if shape.shape_type == MSO_SHAPE_TYPE.TABLE:
        try:
            for row in shape.table.rows:
                row_texts = [cell.text.strip() for cell in row.cells if cell.text.strip()]
                if row_texts:
                    text_parts.append(" | ".join(row_texts))
        except:
            pass
    
    if shape.shape_type == MSO_SHAPE_TYPE.GROUP:
        try:
            for child in shape.shapes:
                child_text = extract_text_from_shape(child)
                if child_text:
                    text_parts.append(child_text)
        except:
            pass
    
    if hasattr(shape, "has_chart") and shape.has_chart:
        try:
            if shape.chart.has_title:
                title = shape.chart.chart_title.text_frame.text.strip()
                if title:
                    text_parts.append(f"[×ª×¨×©×™×: {title}]")
        except:
            pass
    
    return "\n".join(text_parts)


def extract_text_from_pptx(file_bytes: bytes) -> list[dict]:
    """×—×™×œ×•×¥ ×˜×§×¡×˜ ××›×œ ×”×©×§×¤×™×."""
    from pptx.enum.shapes import MSO_SHAPE_TYPE
    
    prs = Presentation(io.BytesIO(file_bytes))
    slides_data = []
    
    for slide_num, slide in enumerate(prs.slides, start=1):
        texts = []
        has_visuals = False
        
        for shape in slide.shapes:
            text = extract_text_from_shape(shape)
            if text:
                texts.append(text)
            
            if shape.shape_type == MSO_SHAPE_TYPE.PICTURE:
                has_visuals = True
            if hasattr(shape, "has_chart") and shape.has_chart:
                has_visuals = True
        
        slide_text = "\n".join(texts).strip()
        
        if not slide_text:
            slide_text = "[×©×§×£ ×¢× ×ª××•× ×•×ª/×’×¨×¤×™×§×”]" if has_visuals else "[×©×§×£ ×¨×™×§]"
        
        slides_data.append({"slide_number": slide_num, "text": slide_text})
    
    return slides_data


def extract_text_from_docx(file_bytes: bytes) -> str:
    """×—×™×œ×•×¥ ×˜×§×¡×˜ ×-Word."""
    doc = Document(io.BytesIO(file_bytes))
    return "\n\n".join([p.text for p in doc.paragraphs if p.text.strip()])


def extract_text_from_txt(file_bytes: bytes) -> str:
    """×—×™×œ×•×¥ ×˜×§×¡×˜ ××§×•×‘×¥ ×˜×§×¡×˜."""
    for enc in ["utf-8", "utf-8-sig", "windows-1255", "iso-8859-8", "latin-1"]:
        try:
            return file_bytes.decode(enc)
        except:
            continue
    return file_bytes.decode("utf-8", errors="replace")


# ============================================================
# × ×™×ª×•×— AI
# ============================================================

# System Prompt ××§×¦×•×¢×™ ×œ×‘×“×™×§×ª ××¦×’×•×ª
SYSTEM_PROMPT = """
×ª×¤×§×™×“:
××ª×” ××©××© ×›×‘×•×“×§ ××¦×’×•×ª ××§×¦×•×¢×™. ××˜×¨×ª×š ×”×™× ×œ×‘×—×•×Ÿ ××¦×’×•×ª ×¡×§×™×¨×” ×©×œ ××™×–××™× ×•×œ×¡×¤×§ ×”×¢×¨×•×ª ××“×•×™×§×•×ª, ×××•×§×“×•×ª ×•×‘×¨×•×¨×•×ª, ×ª×•×š ×”×™×¦××“×•×ª ××•×—×œ×˜×ª ×œ×©×™×—×ª ×”×¤×ª×™×—×” ×©×œ ×”××™×–× (Context).

×›×œ×œ×™ ×™×¡×•×“:
1. ×œ×¤× ×™ ×ª×—×™×œ×ª ×”×‘×“×™×§×” × ×“×¨×©×ª ×©×™×—×ª ×¤×ª×™×—×” (Context).
2. ×× ×§×™×™× ×—×•×¡×¨ ×”×ª×××” ×‘×™×Ÿ ×”××¦×’×ª ×œ×©×™×—×ª ×”×¤×ª×™×—×” (×§×”×œ ×™×¢×“, ×ª×—×•×, ×¡×•×’ ××•×¦×¨) â€” ×™×© ×œ×¦×™×™×Ÿ ×–××ª ×‘××¤×•×¨×©.
3. ×”×§×¤×“ ×¢×œ: ×‘×”×™×¨×•×ª, ×¨×¦×£ ×§×¨×™×, ×ª××¦×•×ª ×•×“×™×•×§.

×”× ×—×™×•×ª × ×™×¡×•×— ×œ×”×¢×¨×•×ª:
* ×›×œ ×”×¢×¨×” × ×¤×ª×—×ª ×›×š: "×©×§×£ X â€“ ..."
* ×”×”× ×—×™×•×ª ×—×™×™×‘×•×ª ×œ×”×™×•×ª ×™×©×™×¨×•×ª, ×œ× ×›×œ×œ×™×•×ª.
* ××™×Ÿ ×œ×”×•×¡×™×£ × ×™×¡×•×—×™× ××¨×•×›×™× ××• ×—×–×¨×ª×™×™×.
* ××™×Ÿ ×œ×”×¢×™×¨ ×¢×œ ×©×§×£ ×”××ª×•×“×•×œ×•×’×™×” (×”×ª×¢×œ× ××× ×•).
* ×¡×“×¨ ×”×‘×“×™×§×”: ×œ×¤×™ ×”×¡×“×¨ ×‘××¦×’×ª, ×œ×œ× ××¡×¤×•×¨ ×¤× ×™××™ ×‘×ª×•×š ×”×”×¢×¨×”.

×”× ×—×™×•×ª ×ª×•×›×Ÿ ×¡×¤×¦×™×¤×™×•×ª:
* ×”×’×“×¨×ª ×”×‘×¢×™×” ×•×”×¤×ª×¨×•×Ÿ: ×—×™×™×‘×™× ×œ×”×•×¤×™×¢ ×‘×©×§×¤×™× × ×¤×¨×“×™×. × ×™×¡×•×— ×‘×¤×¡×§×” ×§×¦×¨×” ×•×–×•×¨××ª (×œ× ×‘×•×œ×˜×™×).
    - ×‘×¢×™×”: ×‘×œ×™ × ×™×¡×•×—×™× ××•×—×œ×˜×™× ("×œ× ×§×™×™× ×¤×ª×¨×•×Ÿ"), ×–×”×™×¨×•×ª ×¢× ×¤×ª×¨×•× ×•×ª ×—×œ×§×™×™×.
    - ×¤×ª×¨×•×Ÿ: ×ª×™××•×¨ ×”××¢× ×” ×œ×œ× ×”×©×•×•××” ×œ××ª×—×¨×™× ×›×¨×’×¢.
* × ×ª×•× ×™ ×©×•×§: ××•×ª×¨ ×œ×”×¦×™×’ ×¨×§ × ×ª×•× ×™× ×-2024â€“2025. × ×ª×•× ×™× ×™×©× ×™× ×™×•×ª×¨ -> ×—×•×‘×” ×œ×”×¢×™×¨ ×•×œ×“×¨×•×© ×¢×“×›×•×Ÿ.
* ××ª×—×¨×™×: ××ª×—×¨×™× ×™×©×™×¨×™× ×ª×—×™×œ×”. ×—×•×‘×” ×œ×›×œ×•×œ ××ª×—×¨×™× ×™×©×¨××œ×™×™× ×× ×™×©. ×œ×¦×™×™×Ÿ ×ª××¨×™×š ×œ× ×ª×•× ×™× (×œ××©×œ "× ×›×•×Ÿ ×œ-2019").
* ×¡×§×™×¨×ª ×©×•×•×§×™×: ×¨×§ ×©×•×•×§×™× ×¨×œ×•×•× ×˜×™×™×. ×× ×™×© ×¢×•××¡ - ×œ×”×¢×™×¨ ××” ×œ×”×¡×™×¨.
* ××¡×§× ×•×ª: ×—×•×‘×” ×œ×”×¦×™×’ ×—×¡×¨×•× ×•×ª ××ª×—×¨×™× + ×›×™×•×•×Ÿ ×‘×™×“×•×œ ×‘×¨×•×¨.

×¤×œ×˜ × ×“×¨×©:
×”×—×–×¨ ××š ×•×¨×§ JSON ×ª×§× ×™ ×”××›×™×œ ×¨×©×™××” ×©×œ ××•×‘×™×™×§×˜×™×, ×›××©×¨ ×›×œ ××•×‘×™×™×§×˜ ××›×™×œ:
- "slide_number": ××¡×¤×¨ ×”×©×§×•×¤×™×ª (××¡×¤×¨ ×©×œ×).
- "original_text": ×ª×§×¦×™×¨ ×§×¦×¨ ×©×œ ×ª×•×›×Ÿ ×”×©×§×£ (×¢×“ 100 ×ª×•×•×™×).
- "ai_comment": ×”×”×¢×¨×” ×”××§×¦×•×¢×™×ª ×©×œ×š ×œ×¤×™ ×”×›×œ×œ×™× ×”× "×œ. ×× ×”×©×§×£ ×ª×§×™×Ÿ, ×›×ª×•×‘ "×ª×§×™×Ÿ".
- "status": ××—×“ ××”×‘××™×:
    * "×œ×‘×™×¦×•×¢" - ×™×© ×‘×¢×™×” ×©×“×•×¨×©×ª ×ª×™×§×•×Ÿ
    * "××”×‘×ª×™" - ×”×©×§×£ ××¦×•×™×Ÿ, ×¨××•×™ ×œ×¦×™×•×Ÿ ×—×™×•×‘×™
    * "× ×¤×ª×¨" - ×”×©×§×£ ×ª×§×™×Ÿ, ××™×Ÿ ×”×¢×¨×•×ª
"""


def analyze_slides(slides_data: list[dict], context_text: str, model_name: str = "gemini-2.0-flash") -> list[dict]:
    """× ×™×ª×•×— ×©×§×¤×™× ×¢× Gemini AI ×‘×××¦×¢×•×ª System Prompt ××§×¦×•×¢×™."""
    
    total = len(slides_data)
    
    # ×”×›× ×ª ×ª×•×›×Ÿ ×”×©×§×¤×™×
    slides_content = "\n\n".join([
        f"=== ×©×§×£ {s['slide_number']}/{total} ===\n{s['text']}"
        for s in slides_data
    ])
    
    # ×‘× ×™×™×ª ×”×¤×¨×•××¤×˜ ×”××œ×
    user_prompt = f"""
×©×™×—×ª ×¤×ª×™×—×” (Context):
---
{context_text}
---

××¦×’×ª ×œ×‘×“×™×§×” ({total} ×©×§×¤×™×):
---
{slides_content}
---

×‘×¦×¢ ×‘×“×™×§×” ××§×¦×•×¢×™×ª ×œ×›×œ {total} ×”×©×§×¤×™× ×•×”×—×–×¨ JSON ×‘×œ×‘×“.
"""

    try:
        model = genai.GenerativeModel(
            model_name,
            system_instruction=SYSTEM_PROMPT
        )
        
        response = model.generate_content(
            user_prompt,
            generation_config=genai.GenerationConfig(
                response_mime_type="application/json",
                temperature=0.2,
                max_output_tokens=16384
            )
        )
        
        response_text = response.text.strip()
        
        # × ×™×¡×™×•×Ÿ ×œ×¤×¢× ×— JSON
        try:
            result = json.loads(response_text)
        except json.JSONDecodeError as je:
            # × ×™×¡×™×•×Ÿ ×œ×ª×§×Ÿ JSON ×œ× ×©×œ×
            st.warning(f"âš ï¸ ×ª×©×•×‘×ª AI ×œ× ×ª×§×™× ×”, ×× ×¡×” ×œ×ª×§×Ÿ...")
            
            # ×”×¡×¨×ª backticks ×× ×™×©
            if response_text.startswith("```"):
                response_text = re.sub(r'^```json?\s*', '', response_text)
                response_text = re.sub(r'\s*```$', '', response_text)
            
            try:
                result = json.loads(response_text)
            except:
                st.error(f"âŒ ×œ× × ×™×ª×Ÿ ×œ×¤×¢× ×— ×ª×©×•×‘×ª AI")
                st.code(response_text[:500], language="json")
                result = []
                
    except Exception as e:
        error_msg = str(e)
        
        if "429" in error_msg or "quota" in error_msg.lower() or "resource" in error_msg.lower():
            st.error("âŒ ×—×¨×™×’×” ×××›×¡×ª API - × ×¡×” ×××•×—×¨ ×™×•×ª×¨ ××• ×”×—×œ×£ ××¤×ª×—")
        elif "403" in error_msg and "leaked" in error_msg.lower():
            st.error("âŒ ××¤×ª×— ×”-API ×“×•×•×— ×›×—×©×•×£ - ×¦×•×¨ ××¤×ª×— ×—×“×© ×‘-Google AI Studio")
        elif "404" in error_msg:
            st.error(f"âŒ ××•×“×œ '{model_name}' ×œ× × ××¦× - × ×¡×” ××•×“×œ ××—×¨")
        elif "API_KEY" in error_msg.upper() or "invalid" in error_msg.lower():
            st.error("âŒ ××¤×ª×— API ×œ× ×ª×§×™×Ÿ - ×‘×“×•×§ ××ª ×”××¤×ª×— ×‘×§×•×“")
        else:
            st.error(f"âŒ ×©×’×™××ª API: {error_msg}")
        
        result = []
    
    # ××™×œ×•×™ ×©×§×¤×™× ×—×¡×¨×™×
    returned = {r.get("slide_number") for r in result}
    for slide in slides_data:
        if slide["slide_number"] not in returned:
            result.append({
                "slide_number": slide["slide_number"],
                "original_text": slide["text"][:100],
                "ai_comment": "âš ï¸ ×œ× × ×•×ª×— - ×™×© ×œ×¡×§×•×¨ ×™×“× ×™×ª",
                "status": "×œ×‘×™×¦×•×¢"
            })
    
    return sorted(result, key=lambda x: x.get("slide_number", 0))


# ============================================================
# ×”×¢×¨×•×ª PowerPoint ××§×•×¨×™×•×ª - ×× ×™×¤×•×œ×¦×™×™×ª ZIP/XML
# ============================================================

def escape_xml(text: str) -> str:
    """Escape special XML characters."""
    return (text
            .replace('&', '&amp;')
            .replace('<', '&lt;')
            .replace('>', '&gt;')
            .replace('"', '&quot;')
            .replace("'", '&apos;'))


def create_comment_authors_xml() -> str:
    """×™×¦×™×¨×ª XML ×©×œ ××—×‘×¨×™ ×”×¢×¨×•×ª."""
    return '''<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<p:cmAuthorLst xmlns:p="http://schemas.openxmlformats.org/presentationml/2006/main">
    <p:cmAuthor id="1" name="AI Reviewer" initials="AI" lastIdx="1000" clrIdx="0"/>
</p:cmAuthorLst>'''


def create_slide_comments_xml(comments: list[dict]) -> str:
    """×™×¦×™×¨×ª XML ×©×œ ×”×¢×¨×•×ª ×œ×©×§×£."""
    comments_xml = []
    for c in comments:
        dt = datetime.now().strftime("%Y-%m-%dT%H:%M:%S.000")
        text = escape_xml(c['text'])
        comments_xml.append(f'''
    <p:cm authorId="1" dt="{dt}" idx="{c['idx']}">
        <p:pos x="{c['x']}" y="{c['y']}"/>
        <p:text>{text}</p:text>
    </p:cm>''')
    
    return f'''<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<p:cmLst xmlns:p="http://schemas.openxmlformats.org/presentationml/2006/main">{"".join(comments_xml)}
</p:cmLst>'''


def add_comments_via_zip(pptx_bytes: bytes, analyzed_data: list[dict]) -> tuple[bytes, str]:
    """
    ×”×•×¡×¤×ª ×”×¢×¨×•×ª PowerPoint ××§×•×¨×™×•×ª ×‘×××¦×¢×•×ª ×× ×™×¤×•×œ×¦×™×™×ª ZIP ×™×©×™×¨×”.
    """
    debug_info = []
    
    try:
        # ×¡×™× ×•×Ÿ ×”×¢×¨×•×ª ×œ×¤×™ ×¡×˜×˜×•×¡
        comments_by_slide = {}
        for item in analyzed_data:
            slide_num = item.get("slide_number")
            status = item.get("status", "")
            comment = item.get("ai_comment", "").strip()
            
            # ×“×™×œ×•×’ ×¢×œ ×”×¢×¨×•×ª "×œ× × ×•×ª×—"
            if "×œ× × ×•×ª×—" in comment:
                continue
            
            if status in ["× ×¤×ª×¨", "×œ××—×•×§"] or not comment:
                continue
            
            prefix = "[×œ×‘×™×¦×•×¢]" if status == "×œ×‘×™×¦×•×¢" else "[××”×‘×ª×™]"
            full_comment = f"{prefix} {comment}"
            
            if slide_num not in comments_by_slide:
                comments_by_slide[slide_num] = []
            comments_by_slide[slide_num].append(full_comment)
        
        debug_info.append(f"×©×§×¤×™× ×¢× ×”×¢×¨×•×ª: {list(comments_by_slide.keys())}")
        
        if not comments_by_slide:
            return pptx_bytes, "âš ï¸ ××™×Ÿ ×”×¢×¨×•×ª ×œ×”×•×¡×¤×” (×›×œ ×”×”×¢×¨×•×ª ×‘×¡×˜×˜×•×¡ × ×¤×ª×¨/×œ××—×•×§)"
        
        # ×¤×ª×™×—×ª ×”-PPTX ×›-ZIP
        input_zip = zipfile.ZipFile(io.BytesIO(pptx_bytes), 'r')
        output_buffer = io.BytesIO()
        output_zip = zipfile.ZipFile(output_buffer, 'w', zipfile.ZIP_DEFLATED)
        
        # ×¨×©×™××ª ×›×œ ×”×§×‘×¦×™× ×‘-ZIP
        all_files = input_zip.namelist()
        debug_info.append(f"×§×‘×¦×™× ×‘-PPTX: {len(all_files)}")
        
        # ×§×¨×™××ª [Content_Types].xml
        content_types = input_zip.read('[Content_Types].xml').decode('utf-8')
        
        # ×§×¨×™××ª presentation.xml.rels
        pres_rels_path = 'ppt/_rels/presentation.xml.rels'
        pres_rels = input_zip.read(pres_rels_path).decode('utf-8')
        
        # ×‘×“×™×§×” ×× commentAuthors ×§×™×™×
        has_authors = 'commentAuthors.xml' in content_types
        
        # ×”×•×¡×¤×ª commentAuthors ×× ×œ× ×§×™×™×
        if not has_authors:
            insert_pos = content_types.rfind('</Types>')
            new_type = '<Override PartName="/ppt/commentAuthors.xml" ContentType="application/vnd.openxmlformats-officedocument.presentationml.commentAuthors+xml"/>\n'
            content_types = content_types[:insert_pos] + new_type + content_types[insert_pos:]
            
            rid_matches = re.findall(r'Id="rId(\d+)"', pres_rels)
            max_rid = max([int(r) for r in rid_matches]) if rid_matches else 0
            new_rid = f"rId{max_rid + 1}"
            
            insert_pos = pres_rels.rfind('</Relationships>')
            new_rel = f'<Relationship Id="{new_rid}" Type="http://schemas.openxmlformats.org/officeDocument/2006/relationships/commentAuthors" Target="commentAuthors.xml"/>\n'
            pres_rels = pres_rels[:insert_pos] + new_rel + pres_rels[insert_pos:]
            debug_info.append("× ×•×¦×¨ commentAuthors.xml")
        
        # ××¢×§×‘ ××—×¨ ×§×‘×¦×™ ×”×¢×¨×•×ª ×©× ×•×¦×¨×•
        comments_files_added = []
        slide_rels_to_create = {}  # rels ×—×“×©×™× ×œ×™×¦×™×¨×”
        slide_rels_to_update = {}  # rels ×§×™×™××™× ×œ×¢×“×›×•×Ÿ
        
        comment_idx = 1
        for slide_num, comments in comments_by_slide.items():
            # ×™×¦×™×¨×ª ×¨×©×™××ª ×”×¢×¨×•×ª
            comment_list = []
            for i, text in enumerate(comments):
                comment_list.append({
                    'idx': comment_idx,
                    'text': text,
                    'x': 7000000,
                    'y': 500000 + (i * 1200000)
                })
                comment_idx += 1
            
            # ×™×¦×™×¨×ª XML ×œ×”×¢×¨×•×ª
            comments_xml = create_slide_comments_xml(comment_list)
            comments_filename = f'ppt/comments/comment{slide_num}.xml'
            comments_files_added.append((comments_filename, comments_xml))
            
            # ×”×•×¡×¤×” ×œ-Content_Types
            insert_pos = content_types.rfind('</Types>')
            new_type = f'<Override PartName="/{comments_filename}" ContentType="application/vnd.openxmlformats-officedocument.presentationml.comments+xml"/>\n'
            content_types = content_types[:insert_pos] + new_type + content_types[insert_pos:]
            
            # ×‘×“×™×§×” ×× ×§×™×™× rels ×œ×©×§×£
            slide_rels_path = f'ppt/slides/_rels/slide{slide_num}.xml.rels'
            
            if slide_rels_path in all_files:
                slide_rels_to_update[slide_rels_path] = slide_num
                debug_info.append(f"×©×§×£ {slide_num}: ×™×¢×•×“×›×Ÿ rels ×§×™×™×")
            else:
                # ×™×¦×™×¨×ª rels ×—×“×©
                slide_rels_to_create[slide_rels_path] = slide_num
                debug_info.append(f"×©×§×£ {slide_num}: ×™×™×•×•×¦×¨ rels ×—×“×©")
        
        # ×”×¢×ª×§×ª ×›×œ ×”×§×‘×¦×™× ×¢× ×¢×“×›×•× ×™×
        for item in all_files:
            if item == '[Content_Types].xml':
                output_zip.writestr(item, content_types.encode('utf-8'))
            elif item == pres_rels_path:
                output_zip.writestr(item, pres_rels.encode('utf-8'))
            elif item in slide_rels_to_update:
                # ×¢×“×›×•×Ÿ slide rels ×§×™×™×
                slide_num = slide_rels_to_update[item]
                slide_rels = input_zip.read(item).decode('utf-8')
                
                rid_matches = re.findall(r'Id="rId(\d+)"', slide_rels)
                max_rid = max([int(r) for r in rid_matches]) if rid_matches else 0
                new_rid = f"rId{max_rid + 1}"
                
                insert_pos = slide_rels.rfind('</Relationships>')
                new_rel = f'<Relationship Id="{new_rid}" Type="http://schemas.openxmlformats.org/officeDocument/2006/relationships/comments" Target="../comments/comment{slide_num}.xml"/>\n'
                slide_rels = slide_rels[:insert_pos] + new_rel + slide_rels[insert_pos:]
                
                output_zip.writestr(item, slide_rels.encode('utf-8'))
            else:
                output_zip.writestr(item, input_zip.read(item))
        
        # ×™×¦×™×¨×ª rels ×—×“×©×™× ×œ×©×§×¤×™× ×©××™×Ÿ ×œ×”×
        for rels_path, slide_num in slide_rels_to_create.items():
            new_rels = f'''<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<Relationships xmlns="http://schemas.openxmlformats.org/package/2006/relationships">
<Relationship Id="rId1" Type="http://schemas.openxmlformats.org/officeDocument/2006/relationships/comments" Target="../comments/comment{slide_num}.xml"/>
</Relationships>'''
            output_zip.writestr(rels_path, new_rels.encode('utf-8'))
        
        # ×”×•×¡×¤×ª commentAuthors.xml ×× ×œ× ×§×™×™×
        if not has_authors:
            output_zip.writestr('ppt/commentAuthors.xml', create_comment_authors_xml().encode('utf-8'))
        
        # ×”×•×¡×¤×ª ×§×‘×¦×™ ×”×¢×¨×•×ª
        for filename, xml_content in comments_files_added:
            output_zip.writestr(filename, xml_content.encode('utf-8'))
        
        input_zip.close()
        output_zip.close()
        
        output_buffer.seek(0)
        
        # Debug output
        debug_str = " | ".join(debug_info)
        return output_buffer.getvalue(), f"âœ… × ×•×¡×¤×• {len(comments_files_added)} ×”×¢×¨×•×ª ({debug_str})"
        
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        return pptx_bytes, f"âŒ ×©×’×™××”: {str(e)}"


def add_comments_to_speaker_notes(pptx_bytes: bytes, analyzed_data: list[dict]) -> tuple[bytes, int]:
    """Fallback: ×”×•×¡×¤×ª ×”×¢×¨×•×ª ×œ-Speaker Notes."""
    prs = Presentation(io.BytesIO(pptx_bytes))
    
    added_count = 0
    
    for item in analyzed_data:
        slide_num = item.get("slide_number", 0)
        status = item.get("status", "")
        comment = item.get("ai_comment", "").strip()
        
        # ×“×™×œ×•×’ ×¢×œ ×”×¢×¨×•×ª ×œ× ×¨×œ×•×•× ×˜×™×•×ª
        if "×œ× × ×•×ª×—" in comment:
            continue
        if status in ["× ×¤×ª×¨", "×œ××—×•×§"] or not comment:
            continue
        
        if slide_num < 1 or slide_num > len(prs.slides):
            continue
        
        slide = prs.slides[slide_num - 1]
        
        indicator = "ğŸ”´ ×œ×‘×™×¦×•×¢" if status == "×œ×‘×™×¦×•×¢" else "ğŸ’š ××”×‘×ª×™"
        formatted = f"\n\n{'='*40}\n{indicator} | AI Reviewer:\n{comment}\n{'='*40}"
        
        notes_slide = slide.notes_slide
        tf = notes_slide.notes_text_frame
        existing = tf.text or ""
        
        tf.clear()
        tf.paragraphs[0].text = existing + formatted
        added_count += 1
    
    output = io.BytesIO()
    prs.save(output)
    output.seek(0)
    return output.getvalue(), added_count


def add_comments_to_pptx(pptx_bytes: bytes, analyzed_data: list[dict]) -> tuple[bytes, str]:
    """×”×•×¡×¤×ª ×”×¢×¨×•×ª - × ×™×¡×™×•×Ÿ ××§×•×¨×™×•×ª ×¢× fallback ×œ-Speaker Notes."""
    
    # × ×™×¡×™×•×Ÿ ×¨××©×•×Ÿ: ×”×¢×¨×•×ª ××§×•×¨×™×•×ª
    result_bytes, message = add_comments_via_zip(pptx_bytes, analyzed_data)
    
    if message.startswith("âœ…"):
        return result_bytes, message
    
    # Fallback: Speaker Notes
    try:
        fallback_bytes, count = add_comments_to_speaker_notes(pptx_bytes, analyzed_data)
        if count > 0:
            return fallback_bytes, f"âš ï¸ × ×•×¡×¤×• {count} ×”×¢×¨×•×ª ×œ-Speaker Notes (×”×¢×¨×•×ª ××§×•×¨×™×•×ª: {message})"
        else:
            return pptx_bytes, f"âš ï¸ ×œ× × ×•×¡×¤×• ×”×¢×¨×•×ª ({message})"
    except Exception as e:
        return pptx_bytes, f"âŒ ×©×’×™××”: {e}"


def create_excel_report(analyzed_data: list[dict]) -> bytes:
    """×™×¦×™×¨×ª ×“×•×— Excel."""
    df = pd.DataFrame(analyzed_data)
    df = df.rename(columns={
        "slide_number": "××¡×¤×¨ ×©×§×£",
        "original_text": "×˜×§×¡×˜ ××§×•×¨×™",
        "ai_comment": "×”×¢×¨×ª AI",
        "status": "×¡×˜×˜×•×¡"
    })
    
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="openpyxl") as writer:
        df.to_excel(writer, index=False, sheet_name="× ×™×ª×•×—")
        ws = writer.sheets["× ×™×ª×•×—"]
        for i, col in enumerate(df.columns):
            ws.column_dimensions[chr(65 + i)].width = min(max(df[col].astype(str).str.len().max(), len(col)) + 2, 50)
    
    output.seek(0)
    return output.getvalue()


# ============================================================
# ××¤×œ×™×§×¦×™×” ×¨××©×™×ª
# ============================================================

def main():
    # ×›×•×ª×¨×ª ×¨××©×™×ª ××¢×•×¦×‘×ª
    st.markdown('''
    <div class="main-header">
        <h1 class="main-title">ğŸ¯ ××¢×¨×›×ª ×¡×§×™×¨×ª ××¦×’×•×ª AI</h1>
        <p class="sub-title">× ×ª×— ××ª ×”××¦×’×ª ×©×œ×š ×‘×××¦×¢×•×ª ×‘×™× ×” ××œ××›×•×ª×™×ª ×•×§×‘×œ ×”×¢×¨×•×ª ××§×¦×•×¢×™×•×ª ×™×©×™×¨×•×ª ×œ×ª×•×š PowerPoint</p>
    </div>
    ''', unsafe_allow_html=True)
    
    # ××“×¨×™×š
    with st.expander("â“ ××™×š ×œ×”×©×ª××©?", expanded=False):
        st.markdown("""
        ### ğŸš€ ××“×¨×™×š ××”×™×¨
        
        **1ï¸âƒ£ ×”×¢×œ××ª ×§×‘×¦×™×**
        
        ×”×¢×œ×” ××¦×’×ª PowerPoint ×•×§×•×‘×¥ ×”×§×©×¨ (TXT/DOCX)
        
        **2ï¸âƒ£ × ×™×ª×•×—**
        
        ×œ×—×¥ ×¢×œ "× ×ª×— ××¦×’×ª" ×•×”××ª×Ÿ ×œ×¡×™×•×
        
        **3ï¸âƒ£ ×¢×¨×™×›×”**
        
        ×¡×§×•×¨ ××ª ×”×”×¢×¨×•×ª ×‘×˜×‘×œ×” ×•×¢×“×›×Ÿ ×¡×˜×˜×•×¡×™×
        
        **4ï¸âƒ£ ×”×•×¨×“×”**
        
        ×”×•×¨×“ ××¦×’×ª ×¢× ×”×¢×¨×•×ª ×‘×¤×× ×œ Review
        
        ---
        
        ### ğŸ“Š ×¡×˜×˜×•×¡×™×
        
        | ×¡××œ | ×¡×˜×˜×•×¡ | ×™×ª×•×•×¡×£? |
        |:---:|:------|:-------:|
        | â³ | ×œ×‘×™×¦×•×¢ | âœ… |
        | â¤ï¸ | ××”×‘×ª×™ | âœ… |
        | âœ… | × ×¤×ª×¨ | âŒ |
        | ğŸ—‘ï¸ | ×œ××—×•×§ | âŒ |
        
        ---
        
        ğŸ’¡ ×”×”×¢×¨×•×ª ×™×•×¤×™×¢×• ×‘-**Review > Comments** ×‘×¤××•×•×¨×¤×•×™× ×˜
        """)
    
    st.markdown("---")
    
    # ×¡×¨×’×œ ×¦×“
    with st.sidebar:
        st.markdown("## âš™ï¸ ×”×’×“×¨×•×ª")
        st.markdown("")
        
        # API
        st.markdown("### ğŸ” ×—×™×‘×•×¨ API")
        api_ok = GEMINI_API_KEY and GEMINI_API_KEY != "YOUR_API_KEY_HERE"
        if api_ok:
            st.markdown("âœ… **××—×•×‘×¨** ×œ×©×¨×ª Gemini")
        else:
            st.markdown("âŒ **×œ× ××—×•×‘×¨** - ×¢×“×›×Ÿ ××¤×ª×— API")
        
        st.markdown("---")
        
        # ××•×“×œ
        st.markdown("### ğŸ¤– ××•×“×œ AI")
        model = st.selectbox(
            "×‘×—×™×¨×”",
            ["gemini-2.0-flash", "gemini-1.5-pro-latest", "gemini-1.5-flash-latest"],
            label_visibility="collapsed"
        )
        model_desc = {
            "gemini-2.0-flash": "âš¡ **××”×™×¨** - ××•××œ×¥ ×œ×¨×•×‘ ×”××©×™××•×ª", 
            "gemini-1.5-pro-latest": "ğŸ¯ **××“×•×™×§** - ×œ× ×™×ª×•×— ××¢××™×§", 
            "gemini-1.5-flash-latest": "ğŸš€ **×§×œ** - ×œ× ×™×ª×•×— ××”×™×¨"
        }
        st.markdown(model_desc.get(model, ""))
        
        st.markdown("---")
        
        # ×¡×˜×˜×™×¡×˜×™×§×•×ª ××¢×•×¦×‘×•×ª
        st.markdown("### ğŸ“Š ×¡×˜×˜×™×¡×˜×™×§×•×ª")
        
        if "slides_data" in st.session_state and st.session_state["slides_data"]:
            slides_count = len(st.session_state["slides_data"])
            st.markdown(f"""
            <div style="
                background: linear-gradient(135deg, rgba(99, 102, 241, 0.2) 0%, rgba(139, 92, 246, 0.1) 100%);
                border: 1px solid rgba(99, 102, 241, 0.3);
                border-radius: 12px;
                padding: 1rem;
                margin: 0.5rem 0;
                text-align: center;
            ">
                <div style="font-size: 2.5rem; font-weight: 700; color: #a5b4fc;">{slides_count}</div>
                <div style="font-size: 0.9rem; color: #94a3b8;">×©×§×¤×™× ×‘××¦×’×ª</div>
            </div>
            """, unsafe_allow_html=True)
        
        if "analysis_results" in st.session_state and st.session_state["analysis_results"]:
            df = pd.DataFrame(st.session_state["analysis_results"])
            counts = df["status"].value_counts()
            
            # ×¡×˜×˜×™×¡×˜×™×§×•×ª ×‘×›×¨×˜×™×¡×™×
            st.markdown(f"""
            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 0.5rem; margin-top: 1rem;">
                <div style="
                    background: linear-gradient(135deg, rgba(245, 158, 11, 0.2) 0%, rgba(245, 158, 11, 0.05) 100%);
                    border: 1px solid rgba(245, 158, 11, 0.3);
                    border-radius: 10px;
                    padding: 0.75rem;
                    text-align: center;
                ">
                    <div style="font-size: 1.8rem; font-weight: 700; color: #fcd34d;">â³ {counts.get("×œ×‘×™×¦×•×¢", 0)}</div>
                    <div style="font-size: 0.75rem; color: #94a3b8;">×œ×‘×™×¦×•×¢</div>
                </div>
                <div style="
                    background: linear-gradient(135deg, rgba(16, 185, 129, 0.2) 0%, rgba(16, 185, 129, 0.05) 100%);
                    border: 1px solid rgba(16, 185, 129, 0.3);
                    border-radius: 10px;
                    padding: 0.75rem;
                    text-align: center;
                ">
                    <div style="font-size: 1.8rem; font-weight: 700; color: #6ee7b7;">âœ… {counts.get("× ×¤×ª×¨", 0)}</div>
                    <div style="font-size: 0.75rem; color: #94a3b8;">× ×¤×ª×¨</div>
                </div>
                <div style="
                    background: linear-gradient(135deg, rgba(236, 72, 153, 0.2) 0%, rgba(236, 72, 153, 0.05) 100%);
                    border: 1px solid rgba(236, 72, 153, 0.3);
                    border-radius: 10px;
                    padding: 0.75rem;
                    text-align: center;
                ">
                    <div style="font-size: 1.8rem; font-weight: 700; color: #f9a8d4;">â¤ï¸ {counts.get("××”×‘×ª×™", 0)}</div>
                    <div style="font-size: 0.75rem; color: #94a3b8;">××”×‘×ª×™</div>
                </div>
                <div style="
                    background: linear-gradient(135deg, rgba(239, 68, 68, 0.2) 0%, rgba(239, 68, 68, 0.05) 100%);
                    border: 1px solid rgba(239, 68, 68, 0.3);
                    border-radius: 10px;
                    padding: 0.75rem;
                    text-align: center;
                ">
                    <div style="font-size: 1.8rem; font-weight: 700; color: #fca5a5;">ğŸ—‘ï¸ {counts.get("×œ××—×•×§", 0)}</div>
                    <div style="font-size: 0.75rem; color: #94a3b8;">×œ××—×•×§</div>
                </div>
            </div>
            """, unsafe_allow_html=True)
    
    # ×”×¢×œ××ª ×§×‘×¦×™×
    st.markdown("## ğŸ“‚ ×”×¢×œ××ª ×§×‘×¦×™×")
    st.markdown("")
    
    c1, c2 = st.columns(2)
    
    with c1:
        st.markdown("#### ğŸ“‘ ××¦×’×ª")
        pptx_file = st.file_uploader("PPTX", type=["pptx"], key="pptx", label_visibility="collapsed")
        if pptx_file:
            st.success(f"âœ… {pptx_file.name}")
    
    with c2:
        st.markdown("#### ğŸ’¬ ×”×§×©×¨")
        context_file = st.file_uploader("TXT/DOCX", type=["txt", "docx"], key="ctx", label_visibility="collapsed")
        if context_file:
            st.success(f"âœ… {context_file.name}")
    
    # ×¢×™×‘×•×“ ×§×‘×¦×™×
    slides_data = context_text = None
    
    if pptx_file:
        pptx_file.seek(0)
        pptx_bytes = pptx_file.read()
        st.session_state["pptx_bytes"] = pptx_bytes
        slides_data = extract_text_from_pptx(pptx_bytes)
        st.session_state["slides_data"] = slides_data
    
    if context_file:
        ctx_bytes = context_file.read()
        context_text = extract_text_from_docx(ctx_bytes) if context_file.name.endswith(".docx") else extract_text_from_txt(ctx_bytes)
        st.session_state["context_text"] = context_text
    
    slides_data = slides_data or st.session_state.get("slides_data")
    context_text = context_text or st.session_state.get("context_text")
    
    st.markdown("---")
    
    # × ×™×ª×•×—
    st.markdown("## ğŸ”¬ × ×™×ª×•×— AI")
    st.markdown("")
    
    missing = []
    if not api_ok: missing.append("ğŸ”‘ API")
    if not slides_data: missing.append("ğŸ“‘ ××¦×’×ª")
    if not context_text: missing.append("ğŸ’¬ ×”×§×©×¨")
    
    can_analyze = not missing
    
    if missing:
        st.warning(f"âš ï¸ ×—×¡×¨: {' â€¢ '.join(missing)}")
    else:
        st.success("âœ… ××•×›×Ÿ ×œ× ×™×ª×•×—!")
    
    _, btn_col, _ = st.columns([1, 2, 1])
    with btn_col:
        if st.button("ğŸ”¬ × ×ª×— ××¦×’×ª", disabled=not can_analyze, type="primary", use_container_width=True):
            with st.spinner("â³ ×× ×ª×—... (×¢×“ ×“×§×”)"):
                try:
                    results = analyze_slides(slides_data, context_text, model)
                    st.session_state["analysis_results"] = results
                    
                    # ×‘×“×™×§×” ×× ×”× ×™×ª×•×— ×”×¦×œ×™×—
                    successful = sum(1 for r in results if "×œ× × ×•×ª×—" not in r.get("ai_comment", ""))
                    total = len(results)
                    
                    if successful == total:
                        st.success(f"ğŸ‰ ×”×•×©×œ×! {total} ×©×§×¤×™× × ×•×ª×—×• ×‘×”×¦×œ×—×”")
                        st.balloons()
                    elif successful > 0:
                        st.warning(f"âš ï¸ × ×•×ª×—×• {successful} ××ª×•×š {total} ×©×§×¤×™×")
                    else:
                        st.error("âŒ ×”× ×™×ª×•×— × ×›×©×œ - ×‘×“×•×§ ××ª ××¤×ª×— ×”-API")
                        
                except Exception as e:
                    st.error(f"âŒ ×©×’×™××”: {e}")
    
    st.markdown("---")
    
    # ×ª×•×¦××•×ª
    if st.session_state.get("analysis_results"):
        st.markdown("## ğŸ“‹ ×ª×•×¦××•×ª")
        st.markdown("")
        
        df = pd.DataFrame(st.session_state["analysis_results"]).sort_values("slide_number").reset_index(drop=True)
        
        # ×¡×™×“×•×¨ ×¢××•×“×•×ª - ×¡×˜×˜×•×¡ ××™××™×Ÿ (×¨××©×•×Ÿ ×‘-RTL)
        column_order = ["status", "slide_number", "ai_comment", "original_text"]
        df = df[[col for col in column_order if col in df.columns]]
        
        edited = st.data_editor(
            df,
            use_container_width=True,
            hide_index=True,
            column_config={
                "status": st.column_config.SelectboxColumn(
                    "ğŸ“Š ×¡×˜×˜×•×¡", 
                    options=["×œ×‘×™×¦×•×¢", "× ×¤×ª×¨", "××”×‘×ª×™", "×œ××—×•×§"], 
                    width="small",
                    help="×‘×—×¨ ×¡×˜×˜×•×¡ ×œ×”×¢×¨×”"
                ),
                "slide_number": st.column_config.NumberColumn(
                    "ğŸ”¢ ×©×§×£", 
                    disabled=True, 
                    width="small"
                ),
                "ai_comment": st.column_config.TextColumn(
                    "ğŸ’¬ ×”×¢×¨×ª AI", 
                    width="large",
                    help="× ×™×ª×Ÿ ×œ×¢×¨×•×š ××ª ×”×”×¢×¨×”"
                ),
                "original_text": st.column_config.TextColumn(
                    "ğŸ“„ ×˜×§×¡×˜ ××§×•×¨×™", 
                    disabled=True, 
                    width="medium"
                ),
            },
            column_order=column_order
        )
        
        st.session_state["analysis_results"] = edited.to_dict("records")
        
        st.markdown("---")
        
        # ×”×•×¨×“×”
        st.markdown("## â¬‡ï¸ ×”×•×¨×“×”")
        st.markdown("")
        
        # ×©××™×¨×ª ×©×™× ×•×™×™× ××”×¢×•×¨×š
        st.session_state["analysis_results"] = edited.to_dict("records")
        
        counts = edited["status"].value_counts()
        active = counts.get("×œ×‘×™×¦×•×¢", 0) + counts.get("××”×‘×ª×™", 0)
        
        # ×”×¦×’×ª ×¡×™×›×•×
        st.info(f"ğŸ“Š **{active}** ×”×¢×¨×•×ª ×™×ª×•×•×¡×¤×• ×œ××¦×’×ª (×œ×‘×™×¦×•×¢: {counts.get('×œ×‘×™×¦×•×¢', 0)}, ××”×‘×ª×™: {counts.get('××”×‘×ª×™', 0)})")
        
        # Debug expander
        with st.expander("ğŸ” Debug - ××™×“×¢ ×˜×›× ×™"):
            st.write("×¡×˜×˜×•×¡×™×:")
            st.write(dict(counts))
            st.write("×“×•×’××ª × ×ª×•× ×™×:")
            if st.session_state.get("analysis_results"):
                st.write(st.session_state["analysis_results"][:2])
        
        c1, c2, c3 = st.columns(3)
        
        with c1:
            if st.session_state.get("pptx_bytes"):
                try:
                    result, msg = add_comments_to_pptx(
                        st.session_state["pptx_bytes"], 
                        st.session_state["analysis_results"]
                    )
                    st.caption(msg)
                    st.download_button(
                        "ğŸ“Š ××¦×’×ª + ×”×¢×¨×•×ª", 
                        result, 
                        "××¦×’×ª_×¢×_×”×¢×¨×•×ª.pptx", 
                        "application/vnd.openxmlformats-officedocument.presentationml.presentation",
                        use_container_width=True, 
                        type="primary"
                    )
                except Exception as e:
                    st.error(f"âŒ {e}")
                    import traceback
                    st.code(traceback.format_exc())
            else:
                st.warning("âš ï¸ ×œ× × ××¦××” ××¦×’×ª ××§×•×¨×™×ª")
        
        with c2:
            try:
                excel = create_excel_report(st.session_state["analysis_results"])
                st.download_button("ğŸ“‘ Excel", excel, "×¦'×§×œ×™×¡×˜.xlsx",
                                  "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                  use_container_width=True)
            except Exception as e:
                st.error(f"âŒ {e}")
        
        with c3:
            st.download_button("ğŸ”§ JSON", 
                              json.dumps(st.session_state["analysis_results"], ensure_ascii=False, indent=2),
                              "× ×™×ª×•×—.json", "application/json", use_container_width=True)
    else:
        st.info("ğŸ’¡ ×”×¢×œ×” ×§×‘×¦×™× ×•×”×¤×¢×œ × ×™×ª×•×— ×›×“×™ ×œ×¨××•×ª ×ª×•×¦××•×ª")


if __name__ == "__main__":
    main()
